{"componentChunkName":"component---src-templates-post-template-js","path":"/posts/language-model","result":{"data":{"markdownRemark":{"id":"f395703c-5896-54e3-b0ea-5df831cbd25c","html":"<p>This projects aims to build a language model to distinguish sentences in three languages: Bahasa Melayu, Bahasa Indonesia, Tamil.</p>\n<blockquote>\n<p>Disclaimer: The input data is a romanised version of these languages. It is not my intention to pretend to know these languages.</p>\n</blockquote>\n<h3 id=\"general-methodology\" style=\"position:relative;\"><a href=\"#general-methodology\" aria-label=\"general methodology permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>General Methodology</h3>\n<p>The <em>n-gram</em> model works by tokenising every corpus, and associating the tokens with a label (i.e. a language).</p>\n<p>For example, suppose there are two sentences:</p>\n<ol>\n<li>English: Be Nice</li>\n<li>German: Guten Tag</li>\n</ol>\n<p>The tokeniser will split the sentences like tokens of <code class=\"language-text\">n</code> characters. With <code class=\"language-text\">n=4</code>, the tokenised statements will be:</p>\n<ol>\n<li>English: (Be N), (e Ni), ( Nic), (Nice)</li>\n<li>German: (Gute), (uten), (ten ), (en T), (n Ta), ( Tag)</li>\n</ol>\n<p>As shown, the tokenisation takes into account the whitespace character ’ ’ to represent words. Other customisations to the model I made include:</p>\n<ul>\n<li>Including/ ignoring punctuation</li>\n<li>Case sensitive/ insensitive</li>\n<li>Length of token (currently 4)</li>\n<li>Padding*</li>\n</ul>\n<p>*Padding adds whitespaces before the first character [e.g. (   B), (  Be), ( Be )] and after the last character [e.g. (ice ), (ce  ), (e   )]. Including these tokens will better represent sentences.</p>\n<h3 id=\"evaluation-criteria\" style=\"position:relative;\"><a href=\"#evaluation-criteria\" aria-label=\"evaluation criteria permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Evaluation Criteria</h3>\n<p>The algorithm looks at a sample sentence, and decides which language it belongs to. Note that the algorithm’s prediction could be that the sentence is not a match with any of the languages in the model.</p>\n<p>For example, given the tokenised sentence of “How Nice”, the algorithm performs the following steps:</p>\n<ol>\n<li>For each token in the sentence, how common is the token in each language? The score of token counts is normalised over the total number of tokens in the language. This way, having a high count for every token would not give a very high score. </li>\n<li>All the token counts are multiplied together, to give each language a score.</li>\n<li>Multiplication is used, and there could be a case where the token count in a language is 0. To prevent the case where all scores would be 0, smoothing is used. The count of all tokens is artificially increased by 1.</li>\n</ol>\n<p>The language with the highest score is the prediction result.</p>\n<h3 id=\"prediction-for-other-language\" style=\"position:relative;\"><a href=\"#prediction-for-other-language\" aria-label=\"prediction for other language permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Prediction for “other” language</h3>\n<p>There could be the case where the sample sentence does not match with any of the languages in the model. I’ve come up with two ways to make this calculation:</p>\n<ol>\n<li>The score of the winning language must be at least a threshold value.</li>\n<li>The difference in the score of the winning language and the second winning language must be at least a threshold value. This method requires that a language be definitively the prediction result.</li>\n</ol>\n<p>A combination of both criteria can be used. In both cases, an arbitrary threshold value is involved.</p>\n<h3 id=\"computation-optimisations\" style=\"position:relative;\"><a href=\"#computation-optimisations\" aria-label=\"computation optimisations permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Computation optimisations</h3>\n<p>Since the probabilities <code class=\"language-text\">(count / total number of tokens in language multiplied together many times)</code> end up very small, a logarithm operation is performed to prevent floating point errors.</p>\n<h3 id=\"remarks\" style=\"position:relative;\"><a href=\"#remarks\" aria-label=\"remarks permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Remarks</h3>\n<p>There are nifty methods (such as tokenisation) provided in the natural language toolkit (nltk).</p>\n<p>For more details, do check out the project on <a href=\"https://github.com/pikulet/language-model\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">GitHub</a>.</p>\n<p>The original assignment question can be found <a href=\"https://www.comp.nus.edu.sg/~zhaojin/cs3245_2019/hw1-lang.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">here</a>.</p>","fields":{"slug":"/posts/language-model","tagSlugs":["/tag/nltk/","/tag/n-grams/"]},"frontmatter":{"date":"2019-03-10","description":"Tokenising sentences to distinguish sentences of different languages","tags":["nltk","n-grams"],"title":"Building a Simple Language Model"}}},"pageContext":{"slug":"/posts/language-model"}},"staticQueryHashes":["251939775","3439816877","401334301"]}