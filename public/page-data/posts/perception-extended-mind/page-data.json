{"componentChunkName":"component---src-templates-post-template-js","path":"/posts/perception-extended-mind","result":{"data":{"markdownRemark":{"id":"e84ddc07-e59e-59f1-8d01-b3c8da9cb83b","html":"<blockquote>\n<p>This was a joint presentation with <a href=\"https://www.linkedin.com/in/lynette-chia-99260620b/?originalSubdomain=sg\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Lynette C.</a>. This article is very relavant to computer scientists interested in how we represent AI.</p>\n</blockquote>\n<p>In the previous week of class, we had learnt about how technological developments around us have changed the way we think. Examples of such technologies include timekeeping, writing and television. Andy Clark takes this claim a step further, claiming that these technologies are integral to how we think. </p>\n<h2 id=\"action-oriented-representation\" style=\"position:relative;\"><a href=\"#action-oriented-representation\" aria-label=\"action oriented representation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Action-Oriented Representation</h2>\n<p>Firstly, studies of perceptual adaptation suggest that they are motor-specific. The thach experiment required participants to wear lenses which tilted the view of the dartboard sideways. Over the course of the experiment, participants were able to successfully adapt to the tilted dartboard. However, the experiment then asked participants to instead use their non-dominant hand to throw the darts. Interestingly, the adaptation gained from the first experiment was not retained in the second experiment. </p>\n<p>The Thach experiment then suggests that our internal neural representations are not action-neutral <strong>descriptions</strong> of the world around us. If we had learned to simply “tilt the dartboard back in our brains”, then surely, when using the non-dominant hand, the dartboard in our brains would still be calibrated with the tilt. However, the experimental results show that perception, cognition and action are integrated together and our inner representation of the world is constructed for us to act on it. We represent the world based on how we can act on it.</p>\n<p>Clark supports the theory of action-oriented representations with three claims. </p>\n<h4 id=\"claim-1-we-do-not-need-a-detailed-inner-model-of-the-world\" style=\"position:relative;\"><a href=\"#claim-1-we-do-not-need-a-detailed-inner-model-of-the-world\" aria-label=\"claim 1 we do not need a detailed inner model of the world permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Claim #1: We do not need a detailed inner model of the world</h4>\n<blockquote>\n<p>Daily agent-environment interactions often do not require the construction and use of detailed inner models.</p>\n</blockquote>\n<p>Firstly, multiple experiments have shown how we often do not notice changes to unattended parts of our environment. A prime example would be the popular internet video of a “gorilla basketball” experiment. Participants are asked to count how many times the basketball is passed around during the video. Since all our attention is on the ball, we do not realise that a man dressed as a gorilla had walked across the screen.</p>\n<p>Secondly, researches have created a robot Herbert to collect soft drink cans. Herbert’s programming did not involve any inner representation of the world. He was able to achieve his goal using the following routine:</p>\n<ul>\n<li>Detect obstacles —> he would halt and turn</li>\n<li>Detect table —> scan for cans</li>\n<li>Detect can —> rotate to face can, collect it</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 244px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0747308d7f98b7daf62b541e71ff55f2/0cba8/perception-herbert.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 158.75%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,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'); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n        <source\n          srcset=\"/static/0747308d7f98b7daf62b541e71ff55f2/8ac56/perception-herbert.webp 240w,\n/static/0747308d7f98b7daf62b541e71ff55f2/d4674/perception-herbert.webp 244w\"\n          sizes=\"(max-width: 244px) 100vw, 244px\"\n          type=\"image/webp\"\n        />\n        <source\n          srcset=\"/static/0747308d7f98b7daf62b541e71ff55f2/8ff5a/perception-herbert.png 240w,\n/static/0747308d7f98b7daf62b541e71ff55f2/0cba8/perception-herbert.png 244w\"\n          sizes=\"(max-width: 244px) 100vw, 244px\"\n          type=\"image/png\"\n        />\n        <img\n          class=\"gatsby-resp-image-image\"\n          src=\"/static/0747308d7f98b7daf62b541e71ff55f2/0cba8/perception-herbert.png\"\n          alt=\"Herbert\"\n          title=\"Herbert\"\n          loading=\"lazy\"\n          style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        />\n      </picture>\n  </a>\n    </span></p>\n<h4 id=\"claim-2-actions-can-help-improve-perception\" style=\"position:relative;\"><a href=\"#claim-2-actions-can-help-improve-perception\" aria-label=\"claim 2 actions can help improve perception permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Claim #2: Actions can help improve perception</h4>\n<blockquote>\n<p>Low-level perception may “call” motor routines that yield better perceptual input and hence improve information pickup.</p>\n</blockquote>\n<p>An example of this would be noticing something in your periphery, and turning your body to get a better view of what is there. In this manner, action is integral to the way that we perceive.</p>\n<h4 id=\"claim-3-action-supports-cognition\" style=\"position:relative;\"><a href=\"#claim-3-action-supports-cognition\" aria-label=\"claim 3 action supports cognition permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Claim #3: Action supports cognition</h4>\n<blockquote>\n<p>Real-world actions may sometimes play an important role in the computational process itself.</p>\n</blockquote>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 535px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0e5ef648d8455f8a6debc42b17b3b1c3/b5245/perception-depth.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.08333333333334%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAADeElEQVQ4yx2SWVPTZxSHc9/LdtzqVMCFCoJVKHsDgRD+2ZN/9n35JyQhAYxgqCMBBBQ7hgJhRNnsYh2UwoDNjFDrTGfa6fSqH6JfoV/g6YsX5+I9F895zu+8qt/eHbH+02v0d59y+EuFuecH2AqLPF4qYTWZsVoGcCghEpEwep2Wh/lRioUCU6VVfDNbFEtrlLd+5MWrfV7uHqA6Pj7iu52f6R0rs7axycjkPD3+IZz+ME6zBU2/AY0cZXp+kfnFNZZKy0zOLnBr+hGG8TL3lzZ5UN7m9cFbKse/o6pUKpSfrXPFFMPlDxGJxkhlsyQzWfLjBRy+GGqtlcTQbXK3JsgXisRiccyeMN2D91nZ3mVpc+eD3d7hW1RKKorRItHa3YHBJuHy2ZHMBnp1OiSjCafDgc9hYKU0y9NnqyRSSaLRADqDRJ87weKWAG68ZGfvDa/2K6gkuQ+X10Yw4sbuNqGzWKmua+WTs7V0trUyN5FjbTbNH7uP+O/fv3hf+UFA01jFIG8wQOb2PULxNCtPNth7c4QqOaqQGkmL1Vx80aHlTE0TXd06JscSjMUtlIsKf+6XmBqNUJqIsFfO4zLoCThlwlEFl9OF0WjGYpO5NzWHyuF1YJYthCMR9JLE2soCy4sPeX+4TeXFY55MJ/m2mGY4GcJqMDKTGSBoMzLu0RL3ewjGkoQCQTweH5LBhMrulrG5nKRFNnvfL7O++g3//P2O5dI8MxNZ2tUSHWo9st3BnUGZr7MubGYbIYuBO1EHqXROxJVAUVJk0sOobG43Tl9IZOcmHPLz6946Cw9m8Yje6YstVNWraWzW0tyuZ3bURnHYzYAkE7KZGPf1MTEUJprKoyTSxJUMKtktdIMxIslham/0cq1Jw8XrPXx0roGaa118ermFSw1q0dfScEODpteExeQmKcukPWbuKg6y2TyD4lslBnPC0OXF4Q3Qo/dzoU7Nx1U3OSXMzte2iXcHZy81C/AJsJ9GMezzRjU68S8HZQeyyCzntzCmeEhkCgzlxk6OEsYbimPzRgSgSwBaPtQ5YfbZ1RPgl9TUf8XVG320dui5LtZXd0nEZSd2cURpQGIoaCIRChJRRlC5A2FxKQW7L8mF+m5OVQvD6ibOXG7l/JV2Tlc3UyUM627209apF2VGrTYTsFrx2c10dGpwWyVifhfRxAj/A/aEKUNe3EA9AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n        <source\n          srcset=\"/static/0e5ef648d8455f8a6debc42b17b3b1c3/8ac56/perception-depth.webp 240w,\n/static/0e5ef648d8455f8a6debc42b17b3b1c3/d3be9/perception-depth.webp 480w,\n/static/0e5ef648d8455f8a6debc42b17b3b1c3/e0c9f/perception-depth.webp 535w\"\n          sizes=\"(max-width: 535px) 100vw, 535px\"\n          type=\"image/webp\"\n        />\n        <source\n          srcset=\"/static/0e5ef648d8455f8a6debc42b17b3b1c3/8ff5a/perception-depth.png 240w,\n/static/0e5ef648d8455f8a6debc42b17b3b1c3/e85cb/perception-depth.png 480w,\n/static/0e5ef648d8455f8a6debc42b17b3b1c3/b5245/perception-depth.png 535w\"\n          sizes=\"(max-width: 535px) 100vw, 535px\"\n          type=\"image/png\"\n        />\n        <img\n          class=\"gatsby-resp-image-image\"\n          src=\"/static/0e5ef648d8455f8a6debc42b17b3b1c3/b5245/perception-depth.png\"\n          alt=\"Art piece on depth illusion\"\n          title=\"Art piece on depth illusion\"\n          loading=\"lazy\"\n          style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        />\n      </picture>\n  </a>\n    </span></p>\n<p>In this illusion, the image we are presented with gives an illusion of depth. However, we can simply move our bodies to the left or right and the illusion will disappear. Then, our motion was part of the cognitive process of depth perception.</p>\n<p>In the example of Herbert the robot earlier, Herbert would always rotate their body to face the drink can before picking it up. This motion allowed Herbert’s picking up action to be more simplified, as the action is now deictically binded to having a drink can in front of it. Then, the motion is performing part of the cognitive work needed to pick the can up.</p>\n<h2 id=\"wideware\" style=\"position:relative;\"><a href=\"#wideware\" aria-label=\"wideware permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Wideware</h2>\n<p>Now we now about the importance of action in neural representation. AI researchers have already successfully action-oriented such forms of mental encoding in robots. Maja Mataric once made a robot that navigated a maze, and the robot would encode landmarks in the maze using sensory input and its current direction of motion. </p>\n<p>The question then arises - we represent the world in an action-oriented way. Do we then <strong>think in an action-oriented way?</strong></p>\n<blockquote>\n<p>Wideware: <strong>External media</strong> or <strong>bodily actions</strong> which are themselves performing cognitive or information-processing operations. The most common functions for wideware would be to store, search and transform information.</p>\n</blockquote>\n<h4 id=\"example-1-we-store-information-in-our-environment\" style=\"position:relative;\"><a href=\"#example-1-we-store-information-in-our-environment\" aria-label=\"example 1 we store information in our environment permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Example 1: We store information in our environment</h4>\n<p>By having the option to write down something on a post-it, we free up some mental capacity to perform other sorts of computation. We can simply “write-down what’s in our heads” because we have the ability to use language to symbolically represent our thoughts. </p>\n<p>These external props are useful to us because they have temporal and spatial stability. If a post-it note could randomly disappear, we wouldn’t write on it. Referring back to Deacon’s work, wideware indexically represent our symbolic thoughts. </p>\n<h4 id=\"example-2-we-manipulate-and-think-using-our-environment\" style=\"position:relative;\"><a href=\"#example-2-we-manipulate-and-think-using-our-environment\" aria-label=\"example 2 we manipulate and think using our environment permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Example 2: We manipulate and think using our environment</h4>\n<p>Off-loading information on external media isn’t all that writing does. We use external media as a symbol-manipulating arena. For instance, we write a sentence, then go back to read it and re-organise it multiple times before coming up with the final iteration of our essays. It is not possible to write that finished form of the essay just by penning down what is in our minds. </p>\n<p>Writing in a way has changed the types of cognitive tasks that we perform. We no longer just write, but also re-read and re-write.</p>\n<h4 id=\"example-3-action-is-cognition\" style=\"position:relative;\"><a href=\"#example-3-action-is-cognition\" aria-label=\"example 3 action is cognition permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Example 3: Action is cognition</h4>\n<p>This whole article is on Clark’s work and here’s a video of him <a href=\"https://www.youtube.com/watch?v=kc-TdMjuJRU\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">discussing this very paper</a>. At about the minute mark, he starts talking about the example of people being injected with botox, which makes the facial muscles rigid (it’s normally used to make people look younger). The participants were then presented with emotive sentences The study found that by not being able to make facial expressions (as we normally do in emotive sentences), participants were slower to understand the sentences.</p>\n<p>By not being able to act, participants were not able to think. (This really puts a new twist on what it means to act before you think.)</p>\n<h4 id=\"example-4-the-cognitive-machine-includes-the-environment\" style=\"position:relative;\"><a href=\"#example-4-the-cognitive-machine-includes-the-environment\" aria-label=\"example 4 the cognitive machine includes the environment permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Example 4: The cognitive machine includes the environment</h4>\n<p>The biological build of a bluefin tuna does not explain how it is able to swim so well. Researchers finally cracked this puzzle when they studied bluefin tuna in their natural environment. It is now known that bluefin tuna make use of the eddies and vortices in the water to gain speed. Then, the real swimming machine is not the bluefin tuna, but the bluefin tuna in its proper environment. </p>\n<blockquote>\n<p>The mind is an essentially <strong>situated</strong> brain: a brain at home in its proper bodily, cultural and environmental niche</p>\n</blockquote>\n<h2 id=\"extended-mind-theory\" style=\"position:relative;\"><a href=\"#extended-mind-theory\" aria-label=\"extended mind theory permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Extended Mind Theory</h2>\n<p>With wideware, there is an active externalism of the mind, as we extend our cognitive processes into the physical world. A prime example would be how Alzheimer’s patients relies on the cognitive scaffolding afforded by wideware, such as with:</p>\n<ul>\n<li>Labelling objects in the house</li>\n<li>Memory books with annotated photos of friends and relatives</li>\n<li>Diaries for tasks and events</li>\n<li>Compensating for biological limits on cognition</li>\n</ul>\n<p>When we remove these wideware, we are not just interfering with the environment, but interfering with the person.</p>\n<h2 id=\"further-discussion\" style=\"position:relative;\"><a href=\"#further-discussion\" aria-label=\"further discussion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Further Discussion</h2>\n<ol>\n<li>(Tomasello) What role can wideware play in cumulative cultural transmission?</li>\n<li>Is the internet part of my mind? Your mind? Our mind?</li>\n<li>What are some ethical consequences of the extended mind theory? Example: “Petty crimes” like theft of a diary containing memories</li>\n<li>(Postman) Postman claimed that we are exposed to so much information that is not actionable. How do we represent information that is not action-oriented? What are the consequences of not being able to\nencode information in action-oriented manner?</li>\n</ol>\n<h2 id=\"remarks\" style=\"position:relative;\"><a href=\"#remarks\" aria-label=\"remarks permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Remarks</h2>\n<p>This project was very fun to work with. The full presentation can be found <a href=\"/extended-mind.pdf\">here</a>.</p>","fields":{"slug":"/posts/perception-extended-mind","tagSlugs":["/tag/artificial-intelligence/","/tag/perception/"]},"frontmatter":{"date":"2020-10-19","description":"What exactly constitutes the mind?","tags":["artificial intelligence","perception"],"title":"An Extended Mind (Andy Clark)"}}},"pageContext":{"slug":"/posts/perception-extended-mind"}},"staticQueryHashes":["251939775","3439816877","401334301"]}